{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "flowerclassification_28_march.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOma4jpKeYm6",
        "outputId": "8bd6a8be-cbff-4a45-f1e7-ff0284c9b2e4"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHeMvFpkR-Oe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8R1NyOv9Gv",
        "outputId": "aa61dbe6-1a6a-4081-88d8-e97de42104d8"
      },
      "source": [
        "val_batch = 10\n",
        "train_batch = 20\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        # shear_range=0.4,\n",
        "        # zoom_range=0.3,\n",
        "        validation_split=0.30,\n",
        "        # horizontal_flip=True,\n",
        "        )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/PIAIC/flower-recognition',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=train_batch,\n",
        "        class_mode='categorical',\n",
        "        subset = 'training',\n",
        "        color_mode = 'grayscale',\n",
        "        shuffle = True,\n",
        "        )\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/PIAIC/flower-recognition',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=val_batch,\n",
        "        class_mode='categorical',\n",
        "        subset = 'validation',\n",
        "        color_mode = 'grayscale',\n",
        "        shuffle= True)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3028 images belonging to 5 classes.\n",
            "Found 1295 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR13ZEf7-zus",
        "outputId": "9927204e-9e2e-481d-e2fa-8ad3139551d6"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqDb5wQt9NSe",
        "outputId": "ae168c51-ee58-4c72-b532-7cce1c6a5723"
      },
      "source": [
        "type(train_datagen)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.preprocessing.image.ImageDataGenerator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0JAwzvh9blZ",
        "outputId": "a71eb289-cc12-4bf2-a930-7b958c3cb9af"
      },
      "source": [
        "train_generator[54][1].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnXIKpfthA0z"
      },
      "source": [
        "# for i,j  in enumerate(train_generator):\n",
        "#   print(j[0].shape)\n",
        "#   tf.image.rgb_to_grayscale(j[0])\n",
        "#   print(j[0].shape)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwP_sindj_1P"
      },
      "source": [
        "# tf.image.rgb_to_grayscale(train_generator)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJX4mmZAep91"
      },
      "source": [
        "# batch_size = 32\n",
        "# img_height = 150\n",
        "# img_width = 150"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7hWLXKeK4r"
      },
      "source": [
        "# train_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#   '/content/drive/MyDrive/PIAIC/flower-recognition',\n",
        "#   validation_split=0.2,\n",
        "#   color_mode=\"grayscale\",\n",
        "#   subset=\"training\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSrJiNmDeNUW"
      },
      "source": [
        "# validation_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#   '/content/drive/MyDrive/PIAIC/flower-recognition',\n",
        "#   validation_split=0.2,\n",
        "#   color_mode=\"grayscale\",\n",
        "#   subset=\"validation\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egZwLd-iJDED"
      },
      "source": [
        "# normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4IzDg3jUXj"
      },
      "source": [
        "# normalized_ds = train_generator.map(lambda x, y: (normalization_layer(x), y))\n",
        "# image_batch, labels_batch = next(iter(normalized_ds))\n",
        "# first_image = image_batch[0]\n",
        "# # Notice the pixels values are now in `[0,1]`.\n",
        "# print(np.min(first_image), np.max(first_image))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d16l3zi0iWtP"
      },
      "source": [
        "# normalized_ds_v = validation_generator.map(lambda x, y: (normalization_layer(x), y))\n",
        "# # image_batch_v, labels_batch_v = next(iter(normalized_ds))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFIm0LZyXLQm"
      },
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "# ds_numpy = tfds.as_numpy(normalized_ds)  # Convert `tf.data.Dataset` to Python generator\n",
        "# for ex in ds_numpy:\n",
        "#   # `{'image': np.array(shape=(28, 28, 1)), 'labels': np.array(shape=())}`\n",
        "#   print(ex[1].shape)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDGr-Im-bzI-"
      },
      "source": [
        "# train_data.shape"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYtkPqncb2Ir"
      },
      "source": [
        "# train_label.shape"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVid6Ptjb-S7"
      },
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "# ds_numpy = tfds.as_numpy(normalized_ds_v)  # Convert `tf.data.Dataset` to Python generator\n",
        "# for ex in ds_numpy:\n",
        "#   # `{'image': np.array(shape=(28, 28, 1)), 'labels': np.array(shape=())}`\n",
        "#   train_data= ex[0]\n",
        "#   train_label= ex[1]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfA82yxUjIE_"
      },
      "source": [
        "\n",
        "\n",
        "# first_image_v = image_batch_v[0]\n",
        "# # Notice the pixels values are now in `[0,1]`.\n",
        "# print(np.min(first_image_v), np.max(first_image_v))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjatcv-sOhi"
      },
      "source": [
        "# one_hot_train_labels = to_categorical(labels_batch)\n",
        "# one_hot_test_labels = to_categorical(labels_batch_v)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0kNKV8DatIC"
      },
      "source": [
        "# #MOdels with COnv2D and Maxpooling\n",
        "# model = tf.keras.models.Sequential([\n",
        "#     # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "#     # This is the first convolution\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#     # The second convolution\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     # The third convolution\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     # The fourth convolution\n",
        "#     tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     # Flatten the results to feed into a DNN\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.5),\n",
        "#     # 512 neuron hidden layer\n",
        "#     tf.keras.layers.Dense(512, activation='relu'),\n",
        "#     tf.keras.layers.Dense(5, activation='softmax')\n",
        "# ])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MECEactbpYY2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(100, 100, 1,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(5,  activation='softmax'))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QFL7tA4D0Sa"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBJbtQp1fhfx"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwG7_qctxUBl",
        "outputId": "722669a7-22b7-4a4b-d38e-8024fcbb98d6"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  result = model.fit(\n",
        "          train_generator,\n",
        "          steps_per_epoch = 20,\n",
        "          batch_size = train_batch,\n",
        "          validation_data = validation_generator,\n",
        "          validation_batch_size= val_batch,\n",
        "          epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 3.4273 - accuracy: 0.2652"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAMVOUBUhcj9"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufw4FqsmU-g2"
      },
      "source": [
        "x = result.history.keys()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOKPsS3HWwUn"
      },
      "source": [
        "\n",
        "# Visualize training history\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7p4aMxliqvO"
      },
      "source": [
        "y_pred1 = model.predict(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qhQ6JA_i0YM"
      },
      "source": [
        "y_pred1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRKNoHsBNvdR"
      },
      "source": [
        "list1 = []\n",
        "for i in range(0,len(validation_generator)):\n",
        "  for j in range(0,val_batch):\n",
        "    try:\n",
        "      list1.append(validation_generator[i][1][j].tolist())\n",
        "    except:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9u0xdNxfeHl"
      },
      "source": [
        "np.argmax(y_pred1, axis=1)[0:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVy31j9On2U_"
      },
      "source": [
        "np.argmax(list1[0:30],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-SgD9VNRfD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvcUePAg9OoZ"
      },
      "source": [
        "len(list1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq1gUHQh_rJ5"
      },
      "source": [
        "plt.figure(figsize = (20,20))\n",
        "for i in range(10):\n",
        "    img = train_datagen[600*i][0]\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(train_datagen[600*i][1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}